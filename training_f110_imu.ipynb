{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process for ECD507 Senior Capstone Project - F1Tenth ML Based Autonomous Race Car\n",
    "### Contributors - Charles Hodgins, Rishabh Hegde, Dylan DiGiacomo, and Andrew Meccariello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.6\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrivingDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.csv = pd.read_csv(csv_file, chunksize=10000)\n",
    "        self.data = next(self.csv);\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx,1]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (200, 66))  # Resize using OpenCV\n",
    "        image = image / 255.0  # Normalize pixel values to [0,1]\n",
    "        image = np.transpose(image, (2, 0, 1))  # Change shape to (C, H, W)\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        steering_angle = float(self.data.iloc[idx, 3])\n",
    "        throttle = float(self.data.iloc[idx, 4])\n",
    "        lidar = torch.tensor(ast.literal_eval(self.data.iloc[idx, 2]))\n",
    "        imu_rotation = float(self.data.iloc[idx,5])\n",
    "        imu_linear = float(self.data.iloc[idx,6])\n",
    "               \n",
    "        return image, lidar, torch.tensor([steering_angle, throttle],dtype=torch.float32),torch.tensor([imu_rotation,imu_linear], dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103213\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/media/ecd507/JetsonOrinNano/home/ecd507/training/data/driving_log.csv')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded chunk\n",
      "True\n",
      "Initial size: 10000\n",
      "Filtered throttle: 1009 rows removed\n",
      "Filtered lidar: 12 rows removed\n",
      "Filtered images: 0 rows removed\n",
      "Final size: 8979\n",
      "8979\n",
      "loaded chunk\n",
      "False\n",
      "Initial size: 10000\n",
      "Filtered throttle: 1331 rows removed\n",
      "Filtered lidar: 0 rows removed\n",
      "Filtered images: 0 rows removed\n",
      "Final size: 8669\n",
      "8669\n",
      "loaded chunk\n",
      "False\n",
      "Initial size: 10000\n",
      "Filtered throttle: 371 rows removed\n",
      "Filtered lidar: 0 rows removed\n",
      "Filtered images: 0 rows removed\n",
      "Final size: 9629\n",
      "9629\n",
      "loaded chunk\n",
      "False\n",
      "Initial size: 10000\n",
      "Filtered throttle: 773 rows removed\n",
      "Filtered lidar: 0 rows removed\n",
      "Filtered images: 0 rows removed\n",
      "Final size: 9227\n",
      "9227\n",
      "loaded chunk\n",
      "False\n",
      "Initial size: 10000\n",
      "Filtered throttle: 2644 rows removed\n",
      "Filtered lidar: 0 rows removed\n",
      "Filtered images: 0 rows removed\n",
      "Final size: 7356\n",
      "7356\n",
      "loaded chunk\n",
      "False\n",
      "Initial size: 10000\n",
      "Filtered throttle: 1082 rows removed\n",
      "Filtered lidar: 0 rows removed\n",
      "Filtered images: 0 rows removed\n",
      "Final size: 8918\n",
      "8918\n",
      "loaded chunk\n",
      "False\n",
      "Initial size: 10000\n",
      "Filtered throttle: 1103 rows removed\n",
      "Filtered lidar: 0 rows removed\n",
      "Filtered images: 0 rows removed\n",
      "Final size: 8897\n",
      "8897\n",
      "loaded chunk\n",
      "False\n",
      "Initial size: 10000\n",
      "Filtered throttle: 690 rows removed\n",
      "Filtered lidar: 0 rows removed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/media/ecd507/JetsonOrinNano/home/ecd507/training/data/driving_log.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,chunksize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m):\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloaded chunk\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m     \u001b[43mfilter_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# print(chunk.head())\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m chunk\n",
      "Cell \u001b[0;32mIn[10], line 23\u001b[0m, in \u001b[0;36mfilter_chunk\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     21\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     22\u001b[0m df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 23\u001b[0m df_filtered \u001b[38;5;241m=\u001b[39m df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_valid_image\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiltered images: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbefore_images \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(df_filtered)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows removed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_filtered)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/series.py:4357\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4248\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4249\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4252\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4253\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FrameOrSeriesUnion:\n\u001b[1;32m   4254\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4255\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4256\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4355\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4356\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/apply.py:1043\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1040\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m-> 1043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/apply.py:1098\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1093\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   1096\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> 1098\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1101\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;66;03m# GH 25959 use pd.array instead of tolist\u001b[39;00m\n\u001b[1;32m   1106\u001b[0m     \u001b[38;5;66;03m# so extension arrays can be used\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(pd_array(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/_libs/lib.pyx:2859\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m, in \u001b[0;36mfilter_chunk.<locals>.is_valid_image\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_valid_image\u001b[39m(img_path):\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(img_path) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def filter_chunk(df):\n",
    "    global first_chunk\n",
    "    print(first_chunk)\n",
    "    print(f\"Initial size: {len(df)}\")\n",
    "\n",
    "    def is_valid_image(img_path):\n",
    "        return os.path.exists(img_path) and cv2.imread(img_path) is not None\n",
    "    \n",
    "    df = df.loc[:, ~df.columns.str.contains(\"^Unnamed\")]\n",
    "\n",
    "    before_throttle = len(df)\n",
    "    df = df[df[\"throttle\"] != 0 ]\n",
    "    print(f\"Filtered throttle: {before_throttle - len(df)} rows removed\")\n",
    "\n",
    "    before_lidar = len(df)\n",
    "    df = df[df[\"lidar_list\"] != \"\"]\n",
    "    df = df[pd.notna(df[\"lidar_list\"])]\n",
    "    print(f\"Filtered lidar: {before_lidar - len(df)} rows removed\")\n",
    "\n",
    "    before_images = len(df)\n",
    "    df[\"image_path\"] = df[\"image_path\"].str.strip()\n",
    "    df = df[df[\"image_path\"] != \"\"]\n",
    "    df_filtered = df[df[\"image_path\"].apply(is_valid_image)]\n",
    "    print(f\"Filtered images: {before_images - len(df_filtered)} rows removed\")\n",
    "\n",
    "    print(f\"Final size: {len(df_filtered)}\")\n",
    "    \n",
    "    print(len(df_filtered))\n",
    "    \n",
    "    if first_chunk:\n",
    "        df_filtered.to_csv(\"/media/ecd507/JetsonOrinNano/home/ecd507/training/data/driving_log2.csv\", mode='w', index=False, header=True)\n",
    "        first_chunk = False\n",
    "    else:\n",
    "        df_filtered.to_csv(\"/media/ecd507/JetsonOrinNano/home/ecd507/training/data/driving_log2.csv\", mode='a', index=False, header=False)\n",
    "    # Save the cleaned dataset\n",
    "first_chunk = True\n",
    "\n",
    "for chunk in pd.read_csv(\"/media/ecd507/JetsonOrinNano/home/ecd507/training/data/driving_log.csv\",chunksize = 10000):\n",
    "    print('loaded chunk')\n",
    "    filter_chunk(chunk)\n",
    "    # print(chunk.head())\n",
    "    del chunk\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DrivingDataset('/media/ecd507/JetsonOrinNano/home/ecd507/training/data/driving_log2.csv')\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class IMUMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IMUMLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2, 64),  # 2 input features → 64 neurons\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2)  # 2 outputs (steering, throttle)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "class CameraLidarFusion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CameraLidarFusion, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(4, 64),  # 2 input features → 64 neurons\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2)  # 2 outputs (steering, throttle)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "class FullFusionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CameraLidarFusion, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(6, 64),  # 6 predictions features → 64 neurons\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2)  # 2 outputs (steering, throttle)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0xffffb2fe45b0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ecd507/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "\n",
    "## train for the fusion model of lidar and camera predictions\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # change to cuda when it begins to work\n",
    "print(len(dataset))\n",
    "imu_model = IMUMLP().to(device)\n",
    "criterion = nn.SmoothL1Loss()\n",
    "optimizer = optim.Adam(imu_model.parameters(), lr=0.001, )\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for images,lidar,targets, imu in dataloader:\n",
    "        \n",
    "        imu, targets = imu.to(device), targets.to(device)        \n",
    "        \n",
    "        outputs = imu_model(imu)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(dataloader)}')\n",
    "\n",
    "# Save model\n",
    "torch.save(imu_model.state_dict(), os.path.expanduser('/media/ecd507/JetsonOrinNano/home/ecd507/training/imu_model.pth'))\n",
    "print(\"Model training complete and saved as imu_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
