{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process for ECD507 Senior Capstone Project - F1Tenth ML Based Autonomous Race Car\n",
    "### Contributors - Charles Hodgins, Rishabh Hegde, Dylan DiGiacomo, and Andrew Meccariello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.6\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index from around 100,000 for object avoidance\n",
    "\n",
    "class DrivingDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx,1]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (200, 66))  # Resize using OpenCV\n",
    "        image = image / 255.0  # Normalize pixel values to [0,1]\n",
    "        image = np.transpose(image, (2, 0, 1))  # Change shape to (C, H, W)\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        steering_angle = float(self.data.iloc[idx, 3])\n",
    "        throttle = float(self.data.iloc[idx, 4])\n",
    "        lidar = torch.tensor(ast.literal_eval(self.data.iloc[idx, 2]))\n",
    "               \n",
    "        return image, lidar, torch.tensor([steering_angle, throttle], dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/media/ecd507/JetsonOrinNano/home/ecd507/training/data/driving_log3.csv\")\n",
    "df.columns = [\"timestamp\", \"image_path\",\"lidar_list\",\"steering\", \"throttle\", \"rotational\", \"linear\"]\n",
    "df.to_csv(\"/media/ecd507/JetsonOrinNano/home/ecd507/training/data/driving_log3.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded chunk 1\n",
      "True\n",
      "Initial size: 10000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_filtered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloaded chunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 50\u001b[0m \u001b[43mfilter_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# print(chunk.head())\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m chunk\n",
      "Cell \u001b[0;32mIn[5], line 32\u001b[0m, in \u001b[0;36mfilter_chunk\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     21\u001b[0m df \u001b[38;5;241m=\u001b[39m df[pd\u001b[38;5;241m.\u001b[39mnotna(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlidar_list\u001b[39m\u001b[38;5;124m\"\u001b[39m])]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# print(f\"Filtered lidar: {before_lidar - len(df)} rows removed\")\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# before_images = len(df)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# print(f\"Final size: {len(df_filtered)}\")\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mdf_filtered\u001b[49m))\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_chunk:\n\u001b[1;32m     35\u001b[0m     df_filtered\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/media/ecd507/JetsonOrinNano/home/ecd507/training/data/driving_log2.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_filtered' is not defined"
     ]
    }
   ],
   "source": [
    "def filter_chunk(df):\n",
    "    global first_chunk\n",
    "    print(first_chunk)\n",
    "    print(f\"Initial size: {len(df)}\")\n",
    "\n",
    "    def is_valid_image(img_path):\n",
    "        return os.path.exists(img_path) and cv2.imread(img_path) is not None\n",
    "\n",
    "    \n",
    "    df = df.loc[:, ~df.columns.str.contains(\"^Unnamed\")]\n",
    "\n",
    "    # before_throttle = len(df)\n",
    "    # df = df[df[\"throttle\"] != 0 ]\n",
    "    # df = df[df['throttle'].apply(is_float)].copy()\n",
    "    # df = df[df[\"throttle\"] > 0.1]\n",
    "    \n",
    "    # print(f\"Filtered throttle: {before_throttle - len(df)} rows removed\")\n",
    "\n",
    "    # before_lidar = len(df)\n",
    "    df = df[df[\"lidar_list\"] != \"\"]\n",
    "    df = df[pd.notna(df[\"lidar_list\"])]\n",
    "    # print(f\"Filtered lidar: {before_lidar - len(df)} rows removed\")  \n",
    "    df_filtered = df\n",
    "    # before_images = len(df)\n",
    "    # df[\"image_path\"] = df[\"image_path\"].str.strip()\n",
    "    # df = df[df[\"image_path\"] != \"\"]\n",
    "    # df_filtered = df[df[\"image_path\"].apply(is_valid_image)]\n",
    "    # print(f\"Filtered images: {before_images - len(df_filtered)} rows removed\")\n",
    "\n",
    "    # print(f\"Final size: {len(df_filtered)}\")\n",
    "    \n",
    "    print(len(df_filtered))\n",
    "    \n",
    "    if first_chunk:\n",
    "        df_filtered.to_csv(\"/media/ecd507/JetsonOrinNano/home/ecd507/training/data/driving_log2.csv\", mode='w', index=False, header=True)\n",
    "        first_chunk = False\n",
    "    else:\n",
    "        df_filtered.to_csv(\"/media/ecd507/JetsonOrinNano/home/ecd507/training/data/driving_log2.csv\", mode='a', index=False, header=False)\n",
    "\n",
    "\n",
    "    # Save the cleaned dataset\n",
    "\n",
    "\n",
    "    \n",
    "first_chunk = True\n",
    "index = 0\n",
    "for chunk in pd.read_csv(\"/media/ecd507/JetsonOrinNano/home/ecd507/training/data/driving_log3.csv\",chunksize = 10000):\n",
    "    index+=1\n",
    "    print(f'loaded chunk {index}')\n",
    "    filter_chunk(chunk)\n",
    "    # print(chunk.head())\n",
    "    del chunk\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14449\n"
     ]
    }
   ],
   "source": [
    "dataset = DrivingDataset('/media/ecd507/JetsonOrinNano/home/ecd507/training/data/driving_log2.csv')\n",
    "print(len(dataset))\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32,\n",
    "                        num_workers=4,\n",
    "                        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LidarNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LidarNet, self).__init__()\n",
    "        # expects input size of 721\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=24, kernel_size=10, stride=4) # output: (721-10)/4 + 1 = 178\n",
    "        self.conv2 = nn.Conv1d(in_channels=24, out_channels=36, kernel_size=8, stride=4) # (178-8)/4 + 1 = 43\n",
    "        self.conv3 = nn.Conv1d(in_channels=36, out_channels=48, kernel_size=4, stride=2) # (43-4)/2 + 1 = 20\n",
    "        self.conv4 = nn.Conv1d(in_channels=48, out_channels=64, kernel_size=3, stride=1) # (20 -3)/1 + 1 = 1\n",
    "        self.conv5 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, stride=1) # (18 - 3)/1 + 1 = 16\n",
    "\n",
    "        self.fc1 = nn.Linear(1024, 512)  # (64 * 16) = 1024 -> 512\n",
    "        self.fc2 = nn.Linear(512, 256) # 512 -> 256\n",
    "        self.fc3 = nn.Linear(256, 100) # 256 -> 200\n",
    "        self.fc4 = nn.Linear(100, 10) # 100 -> 10\n",
    "        self.fc_out = nn.Linear(10, 2)  # 10 -> 2 Steering Angle & Speed\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = torch.relu(self.conv4(x))\n",
    "        x = torch.relu(self.conv5(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten to (batch, 1024)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.fc_out(x)  # No activation for raw output\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "batch110\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0xffff2d11e3b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ecd507/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ecd507/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch113\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0xffff2d11e3b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ecd507/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ecd507/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0xffff2d11e3b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ecd507/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ecd507/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch115\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch118\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0xffff2d11e3b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ecd507/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ecd507/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.008174566534271595\n",
      "batch112\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0xffff2d11e3b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ecd507/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ecd507/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0xffff2d11e3b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ecd507/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ecd507/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionErrorException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0xffff2d11e3b0>: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0xffff2d11e3b0>can only test a child process\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ecd507/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "  File \"/home/ecd507/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "        self._shutdown_workers()self._shutdown_workers()\n",
      "\n",
      "  File \"/home/ecd507/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "  File \"/home/ecd507/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "        if w.is_alive():if w.is_alive():\n",
      "\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: AssertionErrorcan only test a child process: \n",
      "can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 0.0033359259734779133\n",
      "batch112\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0xffff2d11e3b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ecd507/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ecd507/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    Exception ignored in: if w.is_alive():\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0xffff2d11e3b0>  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'Traceback (most recent call last):\n",
      "  File \"/home/ecd507/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "\n",
      "    AssertionErrorself._shutdown_workers(): \n",
      "can only test a child process  File \"/home/ecd507/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "\n",
      "    Exception ignored in: if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0xffff2d11e3b0>    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": Traceback (most recent call last):\n",
      "  File \"/home/ecd507/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "can only test a child process\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ecd507/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "Exception ignored in:     if w.is_alive():\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0xffff2d11e3b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ecd507/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "        self._shutdown_workers()\n",
      "  File \"/home/ecd507/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "    if w.is_alive():AssertionError: \n",
      "can only test a child process\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch361\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0xffffb5de4610>>\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch365\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0xffffb5de4610>>  File \"/home/ecd507/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     13\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images,lidar,targets \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     15\u001b[0m     lidar \u001b[38;5;241m=\u001b[39m lidar\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m     lidar, targets \u001b[38;5;241m=\u001b[39m lidar\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1458\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1457\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1458\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1461\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1420\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1417\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1419\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1420\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1422\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1251\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1239\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1251\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1254\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1255\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1256\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/usr/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ecd507/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "    def _clean_thread_parent_frames(KeyboardInterrupt\n",
      ": \n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # change to cuda when it begins to work\n",
    "print(device)\n",
    "model = LidarNet().to(device)\n",
    "criterion = nn.SmoothL1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, )\n",
    "# Training loop\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    batch = 0\n",
    "    for images,lidar,targets in dataloader:\n",
    "        lidar = lidar.unsqueeze(1)\n",
    "        lidar, targets = lidar.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(lidar)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        batch+=1\n",
    "        print(f'batch{batch}',end = '\\r')\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(dataloader)}')\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), os.path.expanduser('~/models/lidar_model.pth'))\n",
    "print(\"Model training complete and saved as lidar_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/media/ecd507/JetsonOrinNano/home/ecd507/training/lidar_model.pth')\n",
    "print(\"Model training complete and saved as lidar_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
