{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process for ECD507 Senior Capstone Project - F1Tenth ML Based Autonomous Race Car\n",
    "### Contributors - Charles Hodgins, Rishabh Hegde, Dylan DiGiacomo, and Andrew Meccariello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.6\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index from around 100,000 for object avoidance\n",
    "\n",
    "class DrivingDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx,1]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (200, 66))  # Resize using OpenCV\n",
    "        image = image / 255.0  # Normalize pixel values to [0,1]\n",
    "        image = np.transpose(image, (2, 0, 1))  # Change shape to (C, H, W)\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        steering_angle = float(self.data.iloc[idx, 3])\n",
    "        throttle = float(self.data.iloc[idx, 4])\n",
    "        lidar = torch.tensor(ast.literal_eval(self.data.iloc[idx, 2]))\n",
    "               \n",
    "        return image, lidar, torch.tensor([steering_angle, throttle], dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecd507/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3579: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/media/ecd507/JetsonOrinNano/home/ecd507/training/data/driving_log.csv')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded chunk\n",
      "True\n",
      "Initial size: 10000\n",
      "Filtered throttle: 1009 rows removed\n",
      "Filtered lidar: 12 rows removed\n",
      "Filtered images: 0 rows removed\n",
      "Final size: 8979\n",
      "8979\n",
      "loaded chunk\n",
      "False\n",
      "Initial size: 10000\n",
      "Filtered throttle: 1331 rows removed\n",
      "Filtered lidar: 0 rows removed\n",
      "Filtered images: 0 rows removed\n",
      "Final size: 8669\n",
      "8669\n",
      "loaded chunk\n",
      "False\n",
      "Initial size: 10000\n",
      "Filtered throttle: 371 rows removed\n",
      "Filtered lidar: 0 rows removed\n",
      "Filtered images: 0 rows removed\n",
      "Final size: 9629\n",
      "9629\n",
      "loaded chunk\n",
      "False\n",
      "Initial size: 10000\n",
      "Filtered throttle: 773 rows removed\n",
      "Filtered lidar: 0 rows removed\n",
      "Filtered images: 0 rows removed\n",
      "Final size: 9227\n",
      "9227\n",
      "loaded chunk\n",
      "False\n",
      "Initial size: 10000\n",
      "Filtered throttle: 2644 rows removed\n",
      "Filtered lidar: 0 rows removed\n",
      "Filtered images: 0 rows removed\n",
      "Final size: 7356\n",
      "7356\n",
      "loaded chunk\n",
      "False\n",
      "Initial size: 10000\n",
      "Filtered throttle: 1082 rows removed\n",
      "Filtered lidar: 0 rows removed\n",
      "Filtered images: 0 rows removed\n",
      "Final size: 8918\n",
      "8918\n",
      "loaded chunk\n",
      "False\n",
      "Initial size: 5232\n",
      "Filtered throttle: 850 rows removed\n",
      "Filtered lidar: 0 rows removed\n",
      "Filtered images: 0 rows removed\n",
      "Final size: 4382\n",
      "4382\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def filter_chunk(df):\n",
    "    global first_chunk\n",
    "    print(first_chunk)\n",
    "    print(f\"Initial size: {len(df)}\")\n",
    "\n",
    "    def is_valid_image(img_path):\n",
    "        return os.path.exists(img_path) and cv2.imread(img_path) is not None\n",
    "    \n",
    "    df = df.loc[:, ~df.columns.str.contains(\"^Unnamed\")]\n",
    "\n",
    "    before_throttle = len(df)\n",
    "    df = df[df[\"throttle\"] != 0 ]\n",
    "    print(f\"Filtered throttle: {before_throttle - len(df)} rows removed\")\n",
    "\n",
    "    before_lidar = len(df)\n",
    "    df = df[df[\"lidar_list\"] != \"\"]\n",
    "    df = df[pd.notna(df[\"lidar_list\"])]\n",
    "    print(f\"Filtered lidar: {before_lidar - len(df)} rows removed\")\n",
    "\n",
    "    before_images = len(df)\n",
    "    df[\"image_path\"] = df[\"image_path\"].str.strip()\n",
    "    df = df[df[\"image_path\"] != \"\"]\n",
    "    df_filtered = df[df[\"image_path\"].apply(is_valid_image)]\n",
    "    print(f\"Filtered images: {before_images - len(df_filtered)} rows removed\")\n",
    "\n",
    "    print(f\"Final size: {len(df_filtered)}\")\n",
    "    \n",
    "    print(len(df_filtered))\n",
    "    \n",
    "    if first_chunk:\n",
    "        df_filtered.to_csv(\"/media/ecd507/JetsonOrinNano/home/ecd507/training/data/driving_log2.csv\", mode='w', index=False, header=True)\n",
    "        first_chunk = False\n",
    "    else:\n",
    "        df_filtered.to_csv(\"/media/ecd507/JetsonOrinNano/home/ecd507/training/data/driving_log2.csv\", mode='a', index=False, header=False)\n",
    "\n",
    "\n",
    "    # Save the cleaned dataset\n",
    "\n",
    "\n",
    "    \n",
    "first_chunk = True\n",
    "\n",
    "for chunk in pd.read_csv(\"/media/ecd507/JetsonOrinNano/home/ecd507/training/data/driving_log.csv\",chunksize = 10000):\n",
    "    print('loaded chunk')\n",
    "    filter_chunk(chunk)\n",
    "    # print(chunk.head())\n",
    "    del chunk\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57160\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = DrivingDataset('/media/ecd507/JetsonOrinNano/home/ecd507/training/data/driving_log2.csv')\n",
    "print(len(dataset))\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LidarNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LidarNet, self).__init__()\n",
    "        # expects input size of 721\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=24, kernel_size=10, stride=4) # output: (721-10)/4 + 1 = 178\n",
    "        self.conv2 = nn.Conv1d(in_channels=24, out_channels=36, kernel_size=8, stride=4) # (178-8)/4 + 1 = 43\n",
    "        self.conv3 = nn.Conv1d(in_channels=36, out_channels=48, kernel_size=4, stride=2) # (43-4)/2 + 1 = 20\n",
    "        self.conv4 = nn.Conv1d(in_channels=48, out_channels=64, kernel_size=3, stride=1) # (20 -3)/1 + 1 = 1\n",
    "        self.conv5 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, stride=1) # (18 - 3)/1 + 1 = 16\n",
    "\n",
    "        self.fc1 = nn.Linear(1024, 512)  # (64 * 16) = 1024 -> 512\n",
    "        self.fc2 = nn.Linear(512, 256) # 512 -> 256\n",
    "        self.fc3 = nn.Linear(256, 100) # 256 -> 200\n",
    "        self.fc4 = nn.Linear(100, 10) # 100 -> 10\n",
    "        self.fc_out = nn.Linear(10, 2)  # 10 -> 2 Steering Angle & Speed\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = torch.relu(self.conv4(x))\n",
    "        x = torch.relu(self.conv5(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten to (batch, 1024)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.fc_out(x)  # No activation for raw output\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # change to cuda when it begins to work\n",
    "print(device)\n",
    "model = LidarNet().to(device)\n",
    "criterion = nn.SmoothL1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, )\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for images,lidar,targets in dataloader:\n",
    "        lidar = lidar.unsqueeze(1)\n",
    "        lidar, targets = lidar.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(lidar)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(dataloader)}')\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), '/media/ecd507/JetsonOinNano/home/ecd507/training/lidar_model.pth')\n",
    "print(\"Model training complete and saved as lidar_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
